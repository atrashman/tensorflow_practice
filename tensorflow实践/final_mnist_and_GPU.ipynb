{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定GPU测试\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "a = tf.constant([1.2,2.2,0.1],name = \"a\")\n",
    "b = tf.constant ([1.0,2.0,3.0],name = \"b\")\n",
    "result = a+b\n",
    "#init_op = tf.global_variables_initializer()  这里的变量都初始化过了\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=False)\n",
    "#config.gpu_options.allow_growth = True#动态申请显存\n",
    "session = tf.Session(config=config)\n",
    "with tf.Session(config=config) as sess:\n",
    "    with tf.device(\"/gpu:1\"):\n",
    "        print(sess.run(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.290464  -9.280622 -55.167946  50.408566  11.722612]]\n"
     ]
    }
   ],
   "source": [
    "#设计神经网络向前传播\n",
    "weight1 = tf.Variable(tf.random_normal([8,5],stddev = 1,seed = 1),name = \"weight1\")#第一层5个节点\n",
    "bias1 = tf.Variable(tf.zeros([1,5]))\n",
    "weight2 = tf.Variable(tf.random_normal([5,5],stddev = 1,seed = 1))#第二层\n",
    "bias2 = tf.Variable(tf.zeros([1,5]))\n",
    "#定义向前传播\n",
    "xs = tf.constant([[1,2,3,4,5,6,7,8]],name = \"xs\",dtype = tf.float32)\n",
    "a = tf.matmul(xs,weight1)\n",
    "a = tf.add(a,bias1)\n",
    "y = tf.matmul(a,weight2)\n",
    "y = tf.add(y,bias2)\n",
    "all_op = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(all_op)\n",
    "    print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.302495\n",
      "[[-0.8113182   1.4845958   0.06614839 -2.4427042   0.09720233]\n",
      " [ 0.5912243   0.5927074  -2.1223874  -0.72289723 -0.05756911]\n",
      " [ 0.6435448  -0.26464468  1.8576094   0.5678417  -0.38462368]\n",
      " [-1.4853433   1.2615813  -0.02447971 -0.2646297   1.5312678 ]\n",
      " [-1.7429771  -0.4382256  -0.5656303   0.32066926  1.1324259 ]]\n",
      "[[-0.8113182   1.4845988   0.06532937 -2.4427042   0.0992484 ]\n",
      " [ 0.59397745  0.5906697  -2.1229296  -0.7221895  -0.05757786]\n",
      " [ 0.6437825  -0.2644888   1.8566332   0.5681105  -0.38317776]\n",
      " [-1.4853433   1.2617711  -0.02530608 -0.2646297   1.5328138 ]\n",
      " [-1.7421483  -0.43849617 -0.56601     0.32169715  1.1315775 ]]\n"
     ]
    }
   ],
   "source": [
    "#神经网络分类\n",
    "#导入数据,和预处理\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "name = ['name','A','B','C','D','E','target']\n",
    "data = pd.read_excel(r'C:\\Users\\abc\\Desktop\\temp.xlsx',header = 0)\n",
    "data.columns = name\n",
    "data.pop('name')\n",
    "\n",
    "#data = data.join(pd.get_dummies(data.target))\n",
    "#data.head(5)\n",
    "mapping = {1: [1,0,0,0,0],2:[0,1,0,0,0],3:[0,0,1,0,0],4:[0,0,0,1,0],5:[0,0,0,0,1]}#怎样用字典表达式写这个?\n",
    "data['target'] = data['target'].map(mapping)\n",
    "target = data.pop('target')\n",
    "target = list(target.values)\n",
    "target = np.array(target)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(data,target, test_size=0.3, random_state=0)\n",
    "#数据预处理\n",
    "#热编码处理标签\n",
    "classes = 5\n",
    "#使用placehoder机制（定义一个位置）\n",
    "#这个模型有个致命缺陷，就是多分类问题的激活函数，二分类才能为sigmoid\n",
    "weight1 = tf.Variable(tf.random_normal([5,5],stddev = 1,seed = 1),name = \"weight1\")#第一层5个节点\n",
    "bias1 = tf.Variable(tf.zeros([1,5]),dtype = tf.float32)\n",
    "weight2 = tf.Variable(tf.random_normal([5,5],stddev = 1,seed = 1))#第二层\n",
    "bias2 = tf.Variable(tf.zeros([1,5]),dtype = tf.float32)\n",
    "#定义向前传播\n",
    "xs = tf.placeholder(tf.float32,shape =(None,5),name = 'input')\n",
    "y_ = tf.placeholder(tf.float32,shape =(None,5),name = 'input')\n",
    "a = tf.matmul(xs,weight1)\n",
    "a = tf.add(a,bias1)\n",
    "a = tf.nn.relu(a)\n",
    "y = tf.matmul(a,weight2)\n",
    "y = tf.add(y,bias2)\n",
    "y = tf.nn.softmax(y)\n",
    "#GPU参数\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "#y_ = tf.one_hot(y_,classes)\n",
    "#定义反向传播\n",
    "cross_entropy = -tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))#定义\n",
    "learning_rate = 0.001\n",
    "#定义反向传播参数\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "#运行train_step就可以启动优化器\n",
    "\n",
    "step = 100#训练轮次\n",
    "batch_size = 10\n",
    "tf.Session(config=config).run(all_op)\n",
    "all_op = tf.global_variables_initializer()\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(all_op)\n",
    "    for i in range(step):\n",
    "        start = i*batch_size\n",
    "        end = min((i+1)*batch_size,len(X_train))\n",
    "        sess.run(train_step,feed_dict = {xs:X_train[start:end],y_:y_train[start:end]})\n",
    "        if i%50==0:\n",
    "            total_cross_entropy = sess.run(cross_entropy,feed_dict ={xs:X_train,y_:y_train})#每隔一段时间输出模型总误差#是不是有叠加entropy？\n",
    "            print(i,total_cross_entropy)  \n",
    "        if end == len(X_train):\n",
    "            break\n",
    "    print(sess.run(weight1))\n",
    "    print(sess.run(weight2))\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(all_op)\n",
    "    temp = sess.run(y,feed_dict = {xs:X_test})\n",
    "temp1 = []\n",
    "for i in range(temp.shape[0]):\n",
    "    max_ = np.argmax(temp[i]) \n",
    "    i = np.zeros([5])\n",
    "    i[max_] = 1\n",
    "    temp1.append(i)\n",
    "temp1-y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3539972 ],\n",
       "       [1.8623776 ],\n",
       "       [0.9386359 ],\n",
       "       [0.9306019 ],\n",
       "       [1.7364984 ],\n",
       "       [1.9444269 ],\n",
       "       [1.1462723 ],\n",
       "       [1.6304936 ],\n",
       "       [2.3553066 ],\n",
       "       [0.4577079 ],\n",
       "       [1.1387763 ],\n",
       "       [0.71998715],\n",
       "       [1.8983144 ],\n",
       "       [1.9846485 ],\n",
       "       [2.6205149 ],\n",
       "       [0.42431557],\n",
       "       [1.2465173 ],\n",
       "       [1.4135623 ],\n",
       "       [1.2602592 ],\n",
       "       [0.9500469 ],\n",
       "       [1.4910152 ],\n",
       "       [2.241445  ],\n",
       "       [1.135291  ],\n",
       "       [2.8446696 ],\n",
       "       [1.4682897 ],\n",
       "       [0.8729176 ],\n",
       "       [2.499122  ],\n",
       "       [1.4275925 ],\n",
       "       [2.894475  ],\n",
       "       [2.3602004 ],\n",
       "       [2.5505965 ],\n",
       "       [1.1910179 ],\n",
       "       [1.7240503 ],\n",
       "       [2.108063  ],\n",
       "       [2.0506706 ],\n",
       "       [2.0828876 ],\n",
       "       [1.8757933 ],\n",
       "       [2.3503175 ],\n",
       "       [1.413803  ],\n",
       "       [0.71637535],\n",
       "       [1.9603761 ],\n",
       "       [1.3804647 ],\n",
       "       [0.3603826 ],\n",
       "       [1.1762816 ],\n",
       "       [1.736786  ],\n",
       "       [0.46622884],\n",
       "       [1.3679407 ],\n",
       "       [1.1805011 ],\n",
       "       [2.2494361 ],\n",
       "       [2.0190647 ],\n",
       "       [1.0406429 ],\n",
       "       [1.8411725 ],\n",
       "       [0.7224796 ],\n",
       "       [1.8104992 ],\n",
       "       [1.5698969 ],\n",
       "       [0.85147965],\n",
       "       [2.0858886 ],\n",
       "       [1.4803519 ],\n",
       "       [1.9234306 ],\n",
       "       [0.6599571 ],\n",
       "       [1.0173845 ],\n",
       "       [1.4438143 ],\n",
       "       [1.7365669 ],\n",
       "       [1.792009  ],\n",
       "       [1.1819354 ],\n",
       "       [0.89639646],\n",
       "       [1.5479183 ],\n",
       "       [1.6974796 ],\n",
       "       [2.1506946 ],\n",
       "       [1.921071  ],\n",
       "       [1.9784027 ],\n",
       "       [0.39069834],\n",
       "       [2.3178248 ],\n",
       "       [0.74386334],\n",
       "       [2.2065217 ],\n",
       "       [1.8007268 ],\n",
       "       [1.3452423 ],\n",
       "       [2.1894724 ],\n",
       "       [0.71270895],\n",
       "       [1.4625645 ],\n",
       "       [1.6104283 ],\n",
       "       [1.2782693 ],\n",
       "       [1.3175486 ],\n",
       "       [1.8336198 ],\n",
       "       [1.2196088 ],\n",
       "       [0.96579057],\n",
       "       [1.4544849 ],\n",
       "       [1.2859689 ],\n",
       "       [2.3253686 ],\n",
       "       [0.7158404 ],\n",
       "       [2.659733  ],\n",
       "       [1.0234388 ],\n",
       "       [1.3295592 ],\n",
       "       [1.6616665 ],\n",
       "       [0.8851813 ],\n",
       "       [1.4181479 ],\n",
       "       [2.2380373 ],\n",
       "       [2.174263  ],\n",
       "       [0.8348925 ],\n",
       "       [2.6613655 ],\n",
       "       [0.79123485],\n",
       "       [0.37560037],\n",
       "       [1.4432352 ],\n",
       "       [0.9267362 ],\n",
       "       [2.4329567 ],\n",
       "       [1.9353424 ],\n",
       "       [0.6504356 ],\n",
       "       [1.3200594 ],\n",
       "       [0.5073256 ],\n",
       "       [1.5881649 ],\n",
       "       [1.7666783 ],\n",
       "       [2.3662543 ],\n",
       "       [1.8818749 ],\n",
       "       [1.9657171 ],\n",
       "       [2.0664988 ],\n",
       "       [1.7969257 ],\n",
       "       [1.3198918 ],\n",
       "       [2.1278164 ],\n",
       "       [0.6422068 ],\n",
       "       [2.8284147 ],\n",
       "       [0.40679324],\n",
       "       [2.820606  ],\n",
       "       [1.6761318 ],\n",
       "       [2.5359514 ],\n",
       "       [1.0361136 ],\n",
       "       [0.9988104 ],\n",
       "       [0.8468367 ],\n",
       "       [1.6197932 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#回归问题：\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#先定义获取layer的函数\n",
    "def get_weight(shape, lambda_,number=None):\n",
    "    bias = tf.Variable(tf.zeros(shape=[1,shape[1]]),dtype = tf.float32)\n",
    "    weight = tf.Variable(tf.random_normal(shape),name = number,dtype = tf.float32)\n",
    "    tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(lambda_)(weight))#wi为变量的正则表达式，并且加入集合\n",
    "    return weight,bias\n",
    "#预处理和设置数据输入\n",
    "dataset_size = 128\n",
    "feature_num = 2\n",
    "batch_size = 10\n",
    "step = dataset_size%batch_size\n",
    "#制作数据集和数据容器\n",
    "\n",
    "x = np.random.rand(dataset_size,feature_num)\n",
    "x4 = x[:,0:2]#narray是不可以改变值的\n",
    "#x__.dtype = np.float32\n",
    "y = np.array([[x1+2*x2+np.random.rand()/10.0-0.05]for x1,x2 in x4],dtype=np.float32)\n",
    "x4.dtype = np.float32\n",
    "x3 = x4[:,0:2]\n",
    "y.reshape(-1,1)\n",
    "result_num = 1\n",
    "x_ = tf.placeholder(tf.float32,shape = (None,2))\n",
    "print (x.dtype)\n",
    "y_ = tf.placeholder(tf.float32,shape = (None,1))\n",
    "\n",
    "#定义每层节点数，包括输入层输出层\n",
    "layer_dimension = [2,10,10,10,1]\n",
    "#隐藏层数目\n",
    "layer_num = len(layer_dimension)\n",
    "#上一层\n",
    "for_layer = x\n",
    "for i in range(1,layer_num):\n",
    "    out_dimension = layer_dimension[i]\n",
    "    #生成当前层权重\n",
    "    weight,bias = get_weight([layer_dimension[i-1],out_dimension],0.01)\n",
    "    #激活函数激活\n",
    "    for_layer = tf.nn.relu(tf.matmul(tf.cast(for_layer,dtype = tf.float32),weight)+bias)\n",
    "#计算损失\n",
    "mse_loss = tf.reduce_mean(tf.square(y_-for_layer))\n",
    "#加入损失集合\n",
    "tf.add_to_collection('losses',mse_loss)\n",
    "loss_total = tf.add_n(tf.get_collection('losses'))#把损失集合全部加起来\n",
    "#设置训练：\n",
    "learning_rate = 0.001\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_total)\n",
    "\n",
    "#GPU参数\n",
    "#config = tf.ConfigProto(allow_soft_placement=True)\n",
    "step = 12\n",
    "all_op = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "tf.Session(config=config).run(all_op)\n",
    "with tf.Session(config=config) as sess:\n",
    "    for i in range(step):\n",
    "        start = 0*batch_size\n",
    "        end = start+batch_size\n",
    "        sess.run(train_step,feed_dict={x_:x3[start:end],y_:y[start:end]})\n",
    "        sess.run(train_step,feed_dict={x_:x3,y_:y})#有验证集这里换成验证集\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a9ebbb342f34>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\abc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\abc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\abc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\abc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\abc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#运用所有优化方法\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.1162\n",
      "1000 : 0.094\n",
      "2000 : 0.0634\n",
      "3000 : 0.0696\n",
      "4000 : 0.123\n",
      "5000 : 0.1276\n",
      "6000 : 0.102\n",
      "7000 : 0.0966\n",
      "8000 : 0.1218\n",
      "9000 : 0.0484\n",
      "10000 : 0.163\n",
      "11000 : 0.104\n",
      "12000 : 0.0878\n",
      "13000 : 0.0704\n",
      "14000 : 0.0876\n",
      "15000 : 0.1364\n",
      "16000 : 0.0692\n",
      "17000 : 0.0802\n",
      "18000 : 0.1036\n",
      "19000 : 0.1094\n",
      "20000 : 0.1172\n",
      "21000 : 0.1128\n",
      "22000 : 0.0778\n",
      "23000 : 0.1086\n",
      "24000 : 0.085\n",
      "25000 : 0.0768\n",
      "26000 : 0.115\n",
      "27000 : 0.1056\n",
      "28000 : 0.1084\n",
      "29000 : 0.1\n",
      "final_accuracy: 0.109\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\vs2017\\Anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#minst运用所有方法包括正则化，移动平滑\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "#神经网络参数 （一个隐藏层）\n",
    "layer_size = 500\n",
    "batch_size = 100#随机梯度下降法\n",
    "learning_rate_origin = 0.8 #初始学习率\n",
    "learning_rate_decay = 0.99#衰减率\n",
    "lambda_ = 0.0001#正则化lambda\n",
    "train_srep = 30000#训练轮次\n",
    "moving_average_decay = 0.99\n",
    "#辅助函数，给定参数计算向前传播结果\n",
    "#Relu的三层全连接\n",
    "def inference(input_tensor,avg_class,weights1,biases1,weights2,biases2):\n",
    "    if avg_class ==None:#未提供滑动平均\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,weights1)+biases1)\n",
    "        #计算损失函数时使用softmax先激活\n",
    "        return tf.matmul(layer1,weights2)+biases2\n",
    "    else :#先计算滑动平均再向前传播\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,avg_class.average(weights1))+avg_class.average(biases1))\n",
    "        return tf.matmul(layer1,avg_class.average(weights2))+avg_class.average(biases2)\n",
    "#模型训练过程\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32,[None,input_size],name = 'input')\n",
    "    y_ = tf.placeholder(tf.float32,[None,10],name = 'output')\n",
    "    weights1 = tf.Variable(tf.truncated_normal([input_size,layer_size],stddev = 0.1))#784 * 500\n",
    "    biases1 =  tf.Variable(tf.constant(0.1,shape = [layer_size]))\n",
    "    #输出层\n",
    "    weights2 = tf.Variable(tf.truncated_normal([layer_size,output_size],stddev = 0.1))\n",
    "    biases2 =  tf.Variable(tf.constant(0.1,shape = [output_size]))\n",
    "    #不使用滑动平均\n",
    "    #y = inference(x,None,weights1,biases1,weights2,biases2)\n",
    "    global_step = tf.Variable(0,trainable=False)\n",
    "    #初始化平滑\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay,global_step)\n",
    "    variable_op = variable_averages.apply(tf.trainable_variables())\n",
    "    average_y = inference(x,variable_averages,weights1,biases1,weights2,biases2)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_, 1), logits=average_y)\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(lambda_)\n",
    "    regularization = regularizer(weights1)+regularizer(weights2)\n",
    "    loss = cross_entropy_mean+regularization \n",
    "    #设置指数衰减率\n",
    "    #global_step#当前迭代轮次\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate_origin,global_step,mnist.train.num_examples/batch_size,learning_rate_decay)\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step = global_step)\n",
    "#同时完成反向传播的更新参数和滑动平均的更新参数\n",
    "    train_op = tf.group(train_step,variable_op)\n",
    "#预测是否正确\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    all_op = tf.global_variables_initializer()\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(all_op)\n",
    "        validate_feed = {x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        test_feed = {x:mnist.test.images,y_:mnist.test.labels}\n",
    "        for i in range(train_srep):\n",
    "            if i % 1000 == 0:\n",
    "                sess.run(all_op)\n",
    "                print(str(i),':',sess.run(accuracy,feed_dict = validate_feed))\n",
    "        xs,ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_op,feed_dict = {x:xs,y_:ys})\n",
    "        test_acc = sess.run(accuracy,feed_dict=test_feed)\n",
    "        print('final_accuracy:',test_acc)\n",
    "#主程序\n",
    "def main(argv = None):\n",
    "    train(mnist)\n",
    "if __name__ =='__main__':\n",
    "    tf.app.run()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用tensorflow查询机器上是否存在可用的gpu设备\n",
    "def is_gpu_available(cuda_only=True):\n",
    "  \"\"\"\n",
    "  code from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/test.py\n",
    "  Returns whether TensorFlow can access a GPU.\n",
    "  Args:\n",
    "    cuda_only: limit the search to CUDA gpus.\n",
    "  Returns:\n",
    "    True iff a gpu device of the requested kind is available.\n",
    "  \"\"\"\n",
    "  from tensorflow.python.client import device_lib as _device_lib\n",
    " \n",
    "  if cuda_only:\n",
    "    return any((x.device_type == 'GPU')\n",
    "               for x in _device_lib.list_local_devices())\n",
    "  else:\n",
    "    return any((x.device_type == 'GPU' or x.device_type == 'SYCL')\n",
    "               for x in _device_lib.list_local_devices())\n",
    "#使用tensorflow获取可用的gpu设备编号\n",
    "\n",
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "    code from http://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "    \"\"\"\n",
    "    from tensorflow.python.client import device_lib as _device_lib\n",
    "    local_device_protos = _device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as ses:\n",
    "    with tf.device(\"/gpu:1\"):\n",
    "        matrix1=tf.constant([[3.,3.]])\n",
    "        matrix2=tf.constant([[2.],[2.]])\n",
    "        product=tf.matmul(matrix1,matrix2)\n",
    "        ses.run(product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
